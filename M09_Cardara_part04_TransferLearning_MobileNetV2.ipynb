{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab92ee52-bece-428d-845f-1c9a88efe30f",
   "metadata": {},
   "source": [
    "## Paso 4 – Transfer Learning con MobileNetV2\n",
    "\n",
    "En este notebook se desarrolla el punto 4 del caso práctico:\n",
    "\n",
    "**\"Modelo basado en transfer learning\"**\n",
    "\n",
    "En esta sección se implementa un modelo de clasificación mediante *transfer learning*, reutilizando una red neuronal convolucional preentrenada (**MobileNetV2**) y añadiendo una nueva \"cabeza\" personalizada para adaptarla a nuestro problema de clasificación de 6 clases.\n",
    "\n",
    "### Características del modelo: detalle de cada capa añadida\n",
    "\n",
    "- **`base_model`**  \n",
    "  Modelo base `MobileNetV2`, previamente entrenado sobre ImageNet. Se usa como extractor de características y está congelado (`trainable = False`), por lo que sus pesos no se actualizan durante el entrenamiento.\n",
    "\n",
    "- **`GlobalAveragePooling2D()`**  \n",
    "  Sustituye a `Flatten()` como capa de transición. En lugar de aplanar directamente las salidas del modelo base, realiza un promedio sobre cada mapa de activación. Esto reduce el número de parámetros y mejora la generalización del modelo.\n",
    "\n",
    "- **`Dense(128, activation='relu')`**  \n",
    "  Capa totalmente conectada con 128 neuronas. Utiliza la función de activación ReLU para introducir no linealidad y permitir el aprendizaje de combinaciones más abstractas de las características extraídas por el modelo base.\n",
    "\n",
    "- **`Dropout(0.5)`**  \n",
    "  Durante el entrenamiento, desactiva aleatoriamente el 50% de las neuronas de la capa anterior. Esto reduce la dependencia de ciertas neuronas y ayuda a evitar el sobreajuste (*overfitting*).\n",
    "\n",
    "- **`Dense(6, activation='softmax')`**  \n",
    "  Capa de salida con 6 neuronas, una por cada clase del problema de clasificación. La activación softmax convierte las salidas en probabilidades, lo que permite asignar una clase final a cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c95f2a-af4f-4cbf-b345-6555093c9cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 07:46:45.600959: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-31 07:46:45.619319: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-31 07:46:45.659726: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748677605.718763     343 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748677605.735634     343 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748677605.783823     343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748677605.783914     343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748677605.783924     343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748677605.783928     343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-31 07:46:45.799834: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG16\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from utils.dataloader import load_data_npy, PreprocessedDataGenerator\n",
    "from utils.model_utils import save_model_and_history, save_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7f2d8c-7969-4007-bece-45603bdb1157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargadas imágenes y categorias\n",
      "Dividido conjunto completo para entreno, validación y test\n"
     ]
    }
   ],
   "source": [
    "# --- Carga de datos desde .npy ---\n",
    "images_train, categories_train, images_val, categories_val, images_test, categories_test = load_data_npy()\n",
    "\n",
    "print(\"Cargadas imágenes y categorias\")\n",
    "\n",
    "# --- Generadores ---\n",
    "def preprocess_fn(x):\n",
    "    return mobilenet_preprocess(x)  # o vgg_preprocess(x)\n",
    "\n",
    "# Generadores adaptados\n",
    "train_gen = PreprocessedDataGenerator(images_train, categories_train, preprocess_fn=preprocess_fn, resize_to=(224, 224))\n",
    "val_gen = PreprocessedDataGenerator(images_val, categories_val, shuffle=False, preprocess_fn=preprocess_fn, resize_to=(224, 224))\n",
    "test_gen = PreprocessedDataGenerator(images_test, categories_test, shuffle=False, preprocess_fn=preprocess_fn, resize_to=(224, 224))\n",
    "\n",
    "print(\"Dividido conjunto completo para entreno, validación y test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "598e13aa-da7e-4fb8-8c25-df202d88032b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 09:44:07.274567: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 897ms/step - accuracy: 0.1895 - loss: 1.8419 - val_accuracy: 0.2454 - val_loss: 1.7337\n",
      "Epoch 2/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 910ms/step - accuracy: 0.2154 - loss: 1.7269 - val_accuracy: 0.3057 - val_loss: 1.6390\n",
      "Epoch 3/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 955ms/step - accuracy: 0.2358 - loss: 1.6767 - val_accuracy: 0.2892 - val_loss: 1.6108\n",
      "Epoch 4/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 1s/step - accuracy: 0.2218 - loss: 1.6618 - val_accuracy: 0.3174 - val_loss: 1.5741\n",
      "Epoch 5/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 973ms/step - accuracy: 0.2372 - loss: 1.6452 - val_accuracy: 0.3076 - val_loss: 1.5409\n",
      "Epoch 6/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 1s/step - accuracy: 0.2463 - loss: 1.6340 - val_accuracy: 0.3299 - val_loss: 1.5430\n",
      "Epoch 7/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 1s/step - accuracy: 0.2420 - loss: 1.6231 - val_accuracy: 0.3284 - val_loss: 1.4932\n",
      "Epoch 8/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 1s/step - accuracy: 0.2432 - loss: 1.6199 - val_accuracy: 0.3417 - val_loss: 1.4996\n",
      "Epoch 9/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 993ms/step - accuracy: 0.2429 - loss: 1.6067 - val_accuracy: 0.3593 - val_loss: 1.5285\n",
      "Epoch 10/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 945ms/step - accuracy: 0.2453 - loss: 1.6104 - val_accuracy: 0.3460 - val_loss: 1.5155\n",
      "Epoch 11/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 1s/step - accuracy: 0.2504 - loss: 1.5935 - val_accuracy: 0.3804 - val_loss: 1.5145\n",
      "Epoch 12/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 962ms/step - accuracy: 0.2539 - loss: 1.5958 - val_accuracy: 0.3640 - val_loss: 1.4858\n",
      "Epoch 13/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 952ms/step - accuracy: 0.2561 - loss: 1.5949 - val_accuracy: 0.3554 - val_loss: 1.4489\n",
      "Epoch 14/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 934ms/step - accuracy: 0.2604 - loss: 1.5826 - val_accuracy: 0.3562 - val_loss: 1.4089\n",
      "Epoch 15/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 1s/step - accuracy: 0.2626 - loss: 1.5918 - val_accuracy: 0.3530 - val_loss: 1.4251\n",
      "Epoch 16/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 940ms/step - accuracy: 0.2588 - loss: 1.5770 - val_accuracy: 0.3593 - val_loss: 1.4153\n",
      "Epoch 17/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 983ms/step - accuracy: 0.2583 - loss: 1.5864 - val_accuracy: 0.3659 - val_loss: 1.4121\n",
      "Epoch 18/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 1s/step - accuracy: 0.2669 - loss: 1.5758 - val_accuracy: 0.3671 - val_loss: 1.4062\n",
      "Epoch 19/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.2634 - loss: 1.5708 - val_accuracy: 0.3800 - val_loss: 1.4344\n",
      "Epoch 20/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 1s/step - accuracy: 0.2682 - loss: 1.5612 - val_accuracy: 0.3652 - val_loss: 1.4354\n",
      "Epoch 21/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 1s/step - accuracy: 0.2597 - loss: 1.5764 - val_accuracy: 0.3785 - val_loss: 1.4405\n",
      "Epoch 22/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 992ms/step - accuracy: 0.2626 - loss: 1.5708 - val_accuracy: 0.3644 - val_loss: 1.4692\n",
      "Epoch 23/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1000ms/step - accuracy: 0.2678 - loss: 1.5827 - val_accuracy: 0.3883 - val_loss: 1.4561\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 721ms/step - accuracy: 0.3667 - loss: 1.4133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.3660\n",
      "Modelo guardado en: /opt/notebooks/M9/models/transfer_model.h5\n",
      "Historial guardado en: /opt/notebooks/M9/models/transfer_model_history.json\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Congelar capas convolucionales del modelo base\n",
    "base_model.trainable = False  # para feature extraction\n",
    "\n",
    "# --- Construir modelo con cabeza personalizada ---\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# --- Entrenamiento ---\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    epochs=30,\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "# --- Evaluación ---\n",
    "test_loss, test_acc = model.evaluate(test_gen)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}   |  Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# --- Guardado ---\n",
    "save_model_and_history(model, history, model_path='transfer_model')\n",
    "save_test_results('model_extended_cnn', test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f15e01-c004-49f4-a265-489e41d4fa2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
