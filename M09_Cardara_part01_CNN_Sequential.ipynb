{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "524f4506-6ccd-4fe7-bfaa-56e3babae137",
   "metadata": {},
   "source": [
    "## Paso 1 -  Modelo base (CNN)\n",
    "\n",
    "En este notebook se desarrolla el punto 1 del caso práctico:\n",
    "\n",
    "**\"Modelo base basado en redes neuronales convolucionales\"**\n",
    "\n",
    "La arquitectura de la red es libre, pero debe incluir como mínimo:\n",
    "- una **capa convolucional**,\n",
    "- una **capa de pooling** (el tipo es libre),\n",
    "- seguida de una **capa densa de salida**.\n",
    "\n",
    "> En el siguiente apartado se implementará un modelo más complejo.\n",
    "\n",
    "---\n",
    "\n",
    "### Arquitectura del modelo\n",
    "\n",
    "El modelo desarrollado está compuesto por las siguientes capas:\n",
    "\n",
    "1. **Capa de entrada (`Input`)**  \n",
    "   Define la forma de entrada de las imágenes: `(150, 150, 3)`, correspondiente a imágenes RGB de 150x150 píxeles.\n",
    "\n",
    "2. **Capa convolucional (`Conv2D`)**  \n",
    "   Aplica 32 filtros de tamaño 3x3 para extraer características espaciales de las imágenes.  \n",
    "   Utiliza la función de activación `ReLU` para introducir no linealidad.\n",
    "\n",
    "3. **Capa de agrupamiento (`MaxPooling2D`)**  \n",
    "   Reduce la dimensión espacial seleccionando el valor máximo en una ventana de 2x2.  \n",
    "   Ayuda a disminuir el número de parámetros y a prevenir el sobreajuste.\n",
    "\n",
    "4. **Capa de aplanamiento (`Flatten`)**  \n",
    "   Convierte las características extraídas en un vector unidimensional para conectarlo con las capas densas.\n",
    "\n",
    "5. **Capa densa intermedia (`Dense`)**  \n",
    "   Contiene 64 neuronas con activación `ReLU`. Aprende patrones complejos de alto nivel.\n",
    "\n",
    "6. **Capa de salida (`Dense`)**  \n",
    "   Tiene 6 neuronas (una por clase del dataset), con activación `softmax` para clasificación multiclase.\n",
    "\n",
    "---\n",
    "\n",
    "### Guardado del modelo\n",
    "\n",
    "Una vez entrenado, el modelo y su historial de entrenamiento se guardan en la carpeta `models`.\n",
    "\n",
    "---\n",
    "\n",
    "## Nota importante: estructura modular del proyecto\n",
    "\n",
    "Dado que todos los notebooks comparten las funciones de lectura de datos y guardado de modelos, se han creado dos módulos en la carpeta `utilities`:\n",
    "\n",
    "---\n",
    "\n",
    "### Módulo `dataloader.py`\n",
    "\n",
    "#### ⚙️ Utilidades para la gestión de datos: Generadores personalizados y carga desde `.npy`\n",
    "\n",
    "Este módulo define las herramientas necesarias para cargar y preparar los datos de imagen para su uso en modelos de clasificación con TensorFlow/Keras. Está diseñado para funcionar con arrays NumPy previamente generados (`images.npy` y `categories.npy`), optimizando el uso de memoria y permitiendo configuraciones personalizadas en tiempo de entrenamiento.\n",
    "\n",
    "##### Componentes principales\n",
    "\n",
    "- **`DataGenerator`**: clase derivada de `tf.keras.utils.Sequence` que permite iterar sobre lotes de imágenes en memoria.\n",
    "  - Admite redimensionado automático (`resize_to=(h, w)`).\n",
    "  - Permite normalización de los píxeles (`normalize=True`).\n",
    "  - Implementa barajado de datos al final de cada época.\n",
    "\n",
    "- **`PreprocessedDataGenerator`**: extiende `DataGenerator` para aplicar funciones de preprocesamiento personalizadas (por ejemplo, `preprocess_input` de MobileNet, ResNet, etc.).\n",
    "\n",
    "- **`load_data_npy()`**: función para cargar datos desde archivos NumPy (`images.npy`, `categories.npy`) y dividirlos en:\n",
    "  - Conjunto de entrenamiento (60%)\n",
    "  - Validación (15%)\n",
    "  - Test (25%)\n",
    "  \n",
    "  Las divisiones siguen las proporciones especificadas en el enunciado de la práctica, y permiten trabajar de forma flexible con distintos generadores y modelos.\n",
    "\n",
    "Este módulo está pensado para facilitar la reutilización de datos procesados y entrenar modelos de forma eficiente, tanto en CPU como en GPU.\n",
    "\n",
    "### Módulo` dataloader.py`\n",
    "\n",
    "Este módulo proporciona funciones auxiliares para guardar y cargar modelos entrenados con Keras junto con sus historiales de entrenamiento (`history`). Facilita la gestión de resultados experimentales y permite recuperar modelos guardados para evaluación o reutilización posterior.\n",
    "\n",
    "### Funciones disponibles\n",
    "\n",
    "- **`save_model_and_history(model, history, model_path='model', history_path=None)`**  \n",
    "  Guarda el modelo en formato `.h5` y el historial de entrenamiento como archivo `.json`.  \n",
    "  - Por defecto, los archivos se almacenan en una carpeta `models/` en el directorio raíz del proyecto.\n",
    "  - El nombre del historial se genera automáticamente a partir del nombre del modelo, a menos que se indique explícitamente.\n",
    "\n",
    "- **`load_model_and_history(model_name='model')`**  \n",
    "  Carga un modelo `.h5` y su historial asociado `.json` desde la carpeta `models/`.  \n",
    "  Devuelve una tupla `(modelo, history)` lista para usar en evaluación o visualización.\n",
    "\n",
    "- **`load_history(history_path)`**  \n",
    "  Carga directamente un historial de entrenamiento desde un archivo `.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245912b8-5513-4743-9cd8-13d876915ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 13:45:25.249857: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-27 13:45:25.730969: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-27 13:45:26.073045: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748353526.426095   48528 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748353526.503249   48528 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748353527.285870   48528 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748353527.285944   48528 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748353527.285949   48528 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748353527.285953   48528 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-27 13:45:27.383996: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from utils.dataloader import load_data_npy, DataGenerator\n",
    "from utils.model_utils import save_model_and_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "234dca7f-9004-4fdf-af51-8e419dcaeb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (10220, 150, 150, 3), Validation: (2555, 150, 150, 3), Test: (4259, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos\n",
    "images_train, categories_train, images_val, categories_val, images_test, categories_test = load_data_npy()\n",
    "\n",
    "# Crear generadores\n",
    "train_gen = DataGenerator(images_train, categories_train)\n",
    "val_gen = DataGenerator(images_val, categories_val, shuffle=False)\n",
    "test_gen = DataGenerator(images_test, categories_test, shuffle=False)\n",
    "\n",
    "print(f\"Train: {images_train.shape}, Validation: {images_val.shape}, Test: {images_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a4d9c70-192c-47e2-88c4-7a9a735f57ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 390ms/step - accuracy: 0.4798 - loss: 2.0923 - val_accuracy: 0.6708 - val_loss: 0.8972\n",
      "Epoch 2/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 469ms/step - accuracy: 0.7757 - loss: 0.6521 - val_accuracy: 0.7292 - val_loss: 0.7717\n",
      "Epoch 3/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 379ms/step - accuracy: 0.8781 - loss: 0.3695 - val_accuracy: 0.7503 - val_loss: 0.7747\n",
      "Epoch 4/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 375ms/step - accuracy: 0.9491 - loss: 0.1814 - val_accuracy: 0.7358 - val_loss: 0.9345\n",
      "Epoch 5/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 386ms/step - accuracy: 0.9745 - loss: 0.1076 - val_accuracy: 0.7229 - val_loss: 1.0237\n",
      "Epoch 6/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 541ms/step - accuracy: 0.9794 - loss: 0.0782 - val_accuracy: 0.7335 - val_loss: 1.1910\n",
      "Epoch 7/30\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 498ms/step - accuracy: 0.9939 - loss: 0.0331 - val_accuracy: 0.7354 - val_loss: 1.2245\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 127ms/step - accuracy: 0.7399 - loss: 0.7632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.7387  |  Test Loss: 0.7632\n",
      "Modelo guardado en: /opt/notebooks/M9/models/model_base_cnn.h5\n",
      "Historial guardado en: /opt/notebooks/M9/models/model_base_cnn_history.json\n"
     ]
    }
   ],
   "source": [
    "# Arquitectura CNN base\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(150, 150, 3)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    epochs=30,\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "# Evaluación en test\n",
    "test_loss, test_acc = model.evaluate(test_gen)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}  |  Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Guardar modelo e historial\n",
    "save_model_and_history(\n",
    "    model,\n",
    "    history,\n",
    "    model_path='model_base_cnn'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89a4e7-e59b-4831-8d6c-c2c565b6466c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
